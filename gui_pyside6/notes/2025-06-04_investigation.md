# Backend Parameter Mismatch Investigation (2025-06-04)

## Observed errors
- Running the PySide6 GUI with various backends caused multiple `TypeError` exceptions.
- Example trace from the logs when invoking `gtts` after installation:
  `TypeError: synthesize_to_file() got an unexpected keyword argument 'rate'`.
- Similar errors occurred for `edge_tts`, `demucs`, `tortoise`, `mms`, and `vocos` backends.
- Initial run with `pyttsx3` failed due to missing `pywintypes` module, which is part of `pywin32`.

## Cause
- `MainWindow.on_synthesize` unconditionally calls backend functions with `rate`, `voice`, and `lang` keyword arguments.
- Only the `pyttsx3` and `gtts` backends declare these parameters. Other backends have different signatures.
- When a backend does not accept one of these keywords, Python raises `TypeError`.
- Lines 116-120 in `ui/main_window.py` show the unconditional call:
  ```python
  rate = self.rate_spin.value()
  voice_id = self.voice_combo.currentData()
  lang_code = self.lang_combo.currentData()
  BACKENDS[backend](text, output, rate=rate, voice=voice_id, lang=lang_code)
  ```
- Backends like `pyttsx_backend` and `gtts_backend` accept these parameters, but `edge_tts_backend` and others do not.

## Recommended changes
- Adjust `on_synthesize` so it only passes parameters supported by the selected backend.
  - For example, pass `lang` only for `gtts` and possibly `mms`.
  - Pass `voice` for backends that support voice selection (`pyttsx3`, `edge_tts`).
  - Pass `rate` only where applicable (`pyttsx3`, `edge_tts`, `gtts`).
- Update the GUI to enable/disable widgets depending on the current backend. This is partially implemented but does not control parameter passing.
- While synthesis is running, disable the **Synthesize** button to prevent duplicate requests and gray it out. Re-enable it when synthesis completes or fails.
- Add a **Stop** button next to the playback controls to stop the currently playing audio via `QMediaPlayer.stop()`.
- Consider truncating or warning about very long text inputs to avoid accidentally passing extremely long strings to backends.

These adjustments should eliminate the runtime `TypeError` issues and improve the overall user experience.

## Follow-up 2025-06-04

Implemented dynamic parameter handling in `MainWindow.on_synthesize` so that only
supported keywords are passed to each backend. The synthesize button is now
automatically disabled when no text is entered, the selected backend is not
installed, or synthesis is currently running. Console messages indicate when
synthesis starts and finishes. Further improvements such as a dedicated stop
button are still pending.

## Follow-up 2025-06-05

Errors raised inside a backend prevented the final `update_synthesize_enabled()`
call from executing. As a result the **Synthesize** button stayed disabled after
a failure and the GUI had to be restarted. The `on_synthesize` method now wraps
the backend call in a `try/except/finally` block so the busy flag is always
cleared and the button state recovers even if synthesis fails.

## Follow-up 2025-06-06

While testing on Windows, file paths generated by `create_base_filename()` occasionally included trailing spaces and punctuation from the text snippet. This produced invalid paths such as:
`outputs\2025-06-05_00-24-06__gtts__Meanwhile, I'm \2025-06-05_00-24-06__gtts__Meanwhile, I'm .mp3`
which caused `[Errno 2] No such file or directory` when saving audio.

The helper now strips whitespace and replaces unsafe characters so file names are safe on all platforms. `pyttsx3` and other backends can again save and play output reliably.

## Follow-up 2025-06-07

Additional tests were run with the optional backends after fixing the filename
bug. Several failures were reproduced:

- **demucs** and **vocos** expect an input audio file path. When arbitrary text
  is supplied the libraries call `ffprobe` on that string and abort with a
  "command returned non-zero exit status 1" message. This is not a TTS error but
  a misuse of these tools. The UI should validate that the provided path exists
  and show a clear error if it does not.
- **bark** could not be imported because `extension_bark` failed to install in
  the test environment due to restricted network access.
- **tortoise** raised `'GPT2InferenceModel' object has no attribute 'generate'`
  indicating an outdated dependency; updating the `extension_tortoise` package
  is required but also blocked by the proxy.
- **edge_tts** initially failed to list additional voices with
  `ClientHttpProxyError: 403`. After updating to a newer release the backend now
  reports the full set of voices and works without issues.

These backends currently require internet access both for installation and at
runtime. Offline testing is therefore limited.

## Follow-up 2025-06-08

With outbound network access enabled we attempted to install the optional
backends again. Package downloads worked but `demucs` and `bark` pulled in large
PyTorch dependencies (>1&nbsp;GB) so the install was aborted. `edge_tts`
installed successfully into the per-user venv and voice listing succeeded after
the update. The installation helper now appends the hybrid venv's
`site-packages` directory to `sys.path` so modules installed there can be
imported by the main app.

## UI Layout Notes (2025-06-09)

The PySide6 WebUI currently consists of a single window without separate tabs.
The controls are stacked vertically and include:

- a plain text field for the text to synthesize or the path to an input audio file
- a dropdown to select the TTS backend
- an **Install Backend** button that appears when the chosen backend is missing
- optional voice and language selectors depending on the backend
- a speech rate spin box
- a **Load Audio File** button that only shows for file-based backends (demucs and vocos)
- the **Synthesize** button
- buttons to run the API server, open the output folder and play the last file
- a status label for messages

Backends such as Kokoro and Chatterbox from the React UI are not implemented in
the Hybrid application yet. This overview should help track which features are
already present and which remain to be ported.

## Follow-up 2025-06-10

Implemented two usability improvements:

- Added a **Stop Playback** button that calls `QMediaPlayer.stop()` so the user
  can halt audio playback. The button is enabled when playback starts and
  automatically disables when the player enters the stopped state.
- When the input text exceeds 1000 characters the user is prompted to confirm
  before synthesis proceeds. This should prevent accidentally passing extremely
  long strings to the backends.

## Follow-up 2025-06-11

- Implemented the **Kokoro** backend as an optional TTS engine. Selecting it now
  exposes the full list of Kokoro voices and the wrapper converts the WebUI's
  rate value into Kokoro's speed parameter.
- Added helper `get_kokoro_voices()` so the GUI can populate the voice dropdown.
- Chatterbox support remains on the TODO list.

## Follow-up 2025-06-12

- Added a **Chatterbox** backend wrapper. It loads bundled voice prompts from
  `voices/chatterbox/` and exposes them via `get_chatterbox_voices()`.
- Updated the GUI to list these voices when Chatterbox is selected.

## Follow-up 2025-06-13

- Clarified that Chatterbox can synthesize without a preset voice prompt.
  A file picker allows loading a custom prompt, while bundled samples remain
  optional.
- Introduced a global **Seed** field to reproducibly control random backends.
- Added an **Auto play** checkbox so output is played automatically when
  synthesis succeeds.
- Implemented Chatterbox-specific sliders for **exaggeration**, **CFG/Pace**
  and **temperature**.
- Long operations now run in a background thread to keep the UI responsive.

## Follow-up 2025-06-14

- Backend installation now runs in a separate thread so the UI stays responsive.
- Fixed Kokoro backend import errors by adding the missing `extension_kokoro`
  package requirement.
- Audio file loading for Demucs and Vocos no longer overwrites the text field;
  the selected path is stored separately.
- Chatterbox synthesis now splits long text into 280 character chunks using
  NLTK when available.


## Follow-up 2025-06-15

- The backend selector now hides voice, language, rate and seed controls when the chosen backend does not support them.
- Output paths for file-based backends use the source file name instead of the full path to avoid unwieldy directories.
- `update_synthesize_enabled` checks for a loaded audio file when required.

## Follow-up 2025-06-16

- Initial attempt to detect supported parameters via function signatures failed
  because backends are wrapped in `functools.partial`. Introduced explicit
  `BACKEND_FEATURES` mapping in `backend/__init__.py` and updated the GUI to
  consult this table when showing or hiding controls.
- Restored Synthesize button availability for all backends.
## Status Update 2025-06-17

The following backends are confirmed working and do not require further investigation:
- Chatterbox
- Pyttsx3
- Gtts
- edge_tts
- mms (may need more features later)

Continue focusing on unresolved backends that still fail to install or run.

## Follow-up 2025-06-18

Recent work focused on the **Tortoise** and **Piper** backends. The reference
`extension_tortoise` repository exposes a `generate_tortoise` function that wraps
`TextToSpeech.tts_with_preset`. Parameters are collected in a
`TortoiseParameters` dataclass and include:

- `voice` and `preset` (ultra_fast, fast, standard, high_quality)
- autoregressive settings such as `temperature` and `top_p`
- diffusion settings like `cond_free_k`

A helper `generate_tortoise_long` automatically splits long prompts and yields
`TortoiseOutputUpdate` objects containing the audio, metadata and output
filenames. Voices are loaded with `tortoise.utils.audio.load_voices()` and can be
placed in a local `voices-tortoise` directory. Pre-made voice packs are freely
available from community repos on HuggingFace (e.g.
`https://huggingface.co/jbetker/tortoise-tts`).

The `extension_piper_tts` repository uses `PiperVoice.load()` and the
`synthesize_numpy` helper to generate audio. Required parameters are
`length_scale`, `noise_scale`, `noise_w` and `sentence_silence`. Voice models are
stored under `data/models/piper` and can be downloaded from
`https://huggingface.co/rhasspy/piper-voices`.

The current installation of `extension_tortoise` still fails with
`'GPT2InferenceModel' object has no attribute 'generate'`. Updating to a newer
release should resolve this. Piper has not yet been integrated into the GUI, but
its Python API appears straightforward once a compatible voice model is
available.

## Follow-up 2025-06-19

A review of the already working backends revealed a few advanced parameters that could further improve synthesis quality:

- **Chatterbox** offers `exaggeration`, `cfg_weight` and `temperature` controls. The ComfyUI integration recommends keeping `cfg_weight` around 0.3 for fast voices or raising `exaggeration` above 0.7 for dramatic speech.
- **Pyttsx3** supports adjusting `volume` in addition to `rate` and `voice`. Volume ranges from 0 to 1 and could be exposed through the GUI.
- **gTTS** accepts `slow=True` for a more deliberate reading pace and a `tld` parameter to select accents like `.co.uk` or `.com.au`.
- **edge_tts** exposes `pitch` and `volume` adjustments plus optional speaking styles. Only rate is currently wired up in the GUI.
- **MMS** allows tweaking `speaking_rate`, `noise_scale` and `noise_scale_duration`; these parameters are defined in the backend but not yet surfaced in the interface.

These additions are not required for basic synthesis but may yield higher quality or more expressive results. Implementation effort is low since most knobs already exist in the backend modules.
## UI Enhancement Ideas 2025-06-20

To make the packaged application more flexible, a dedicated **Model Manager** tab could help users install or update optional TTS, voice conversion and music generation modules without leaving the GUI. Features might include:

- Listing all optional backends and their install status using `missing_backend_packages()`.
- Buttons to install, reinstall or remove each backend directly from the interface.
- A sub-section to manage voice packs for engines like Tortoise or Piper by selecting a local folder or URL and copying the files to `voices-tortoise` or similar directories.
- A progress log so users can track installation output when running `pip` in the background.

These additions would let non-technical users manage models after the app is frozen as an executable while keeping the base download small.
